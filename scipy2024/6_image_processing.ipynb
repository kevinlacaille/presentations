{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Raster Bands\n",
    "\n",
    "## Preparing Your Workspace\n",
    "\n",
    "### Option 1: (recommended) Run in Google Colab\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kevinlacaille/presentations/blob/main/scipy2024/6_image_processing.ipynb)\n",
    "\n",
    "### Option 2: Run local Jupyter instance\n",
    "You can also choose to open this Notebook in your own local Jupyter instance.\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- Install: rasterio, exiftool\n",
    "- Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterio\n",
    "!apt-get install -y exiftool\n",
    "!pip install PyExifTool\n",
    "!wget https://raw.githubusercontent.com/kevinlacaille/presentations/main/scipy2024/data/presentation/8928dec4ddbffff/DJI_0876.JPG\n",
    "# Download the zip file\n",
    "!wget https://github.com/kevinlacaille/presentations/raw/main/scipy2024/data/presentation/vancouver_data.zip -O /content/vancouver_data.zip\n",
    "# Unzip the file\n",
    "!unzip /content/vancouver_data.zip -d /content/vancouver_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import exiftool\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bands(image_path):\n",
    "    # Open the image and read the bands as numpy arrays\n",
    "    with rasterio.open(image_path) as src:\n",
    "        blue = src.read(1)\n",
    "        green = src.read(2)\n",
    "        red = src.read(3)\n",
    "    rgb = np.dstack((blue, green, red))\n",
    "    return blue, green, red, rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(image_path):\n",
    "    # Get the metadata of the image\n",
    "    with exiftool.ExifTool() as et:\n",
    "        metadata = json.loads(et.execute(b'-j', image_path))\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gsd(metadata, height=15):\n",
    "    # Extract the GPS Altitude\n",
    "    altitude = float(metadata[0].get(\"XMP:RelativeAltitude\"))\n",
    "    print(f\"Altitude: {altitude} m\")\n",
    "    focal_length = metadata[0].get(\"EXIF:FocalLength\")  # in mm\n",
    "    image_width = metadata[0].get(\"File:ImageWidth\")\n",
    "    # Size of pixel = sensor width (m) / image width (px)\n",
    "    pixel_pitch = 6.17e-3 / image_width\n",
    "    gsd_tree = (altitude - height) * pixel_pitch / (focal_length / 1000)\n",
    "    gsd = (altitude) * pixel_pitch / (focal_length / 1000)\n",
    "    return gsd, gsd_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_size(gsd_tree):\n",
    "    diameter_of_tree = 10  # meters\n",
    "\n",
    "    # Number of pixels the tree will cover\n",
    "    diameter_of_tree_px = diameter_of_tree / gsd_tree\n",
    "    area_of_tree = np.pi * (diameter_of_tree_px / 2)**2\n",
    "    # Kernel size for morphological operations\n",
    "    kernel_size = int(np.sqrt(diameter_of_tree_px))\n",
    "    # Ensure kernel size is odd\n",
    "    if kernel_size % 2 == 0:\n",
    "        kernel_size += 1\n",
    "    print(f\"Kernel size: {kernel_size}\")\n",
    "    return area_of_tree, kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vari(blue, green, red):\n",
    "    # Calculate the VARI index\n",
    "    vari = (green.astype(float) - red.astype(float)) / (\n",
    "        green.astype(float) + red.astype(float) - blue.astype(float))\n",
    "    return vari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(vari, vari_min=0.1, vari_max=0.5):\n",
    "    # Generate the vegetation mask\n",
    "    vegetation_mask = np.full(vari.shape, np.nan)\n",
    "    vegetation_mask[(vari >= vari_min)] = 1\n",
    "\n",
    "    # Generate the non-vegetation mask\n",
    "    non_vegetation_mask = np.full(vari.shape, np.nan)\n",
    "    non_vegetation_mask[vari < vari_min] = 1\n",
    "\n",
    "    return vegetation_mask, non_vegetation_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(mask, kernel_size=7):\n",
    "    # Apply a Gaussian blur to the mask\n",
    "    blur = cv.GaussianBlur(mask, (kernel_size, kernel_size), 0)\n",
    "    return blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphological_operations(mask, kernel_size=18):\n",
    "    # Apply opening and closing morphological operations to the mask\n",
    "\n",
    "    opening_kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    opening = cv.morphologyEx(mask, cv.MORPH_OPEN, opening_kernel)\n",
    "\n",
    "    closing_kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    closing = cv.morphologyEx(opening, cv.MORPH_CLOSE, closing_kernel)\n",
    "\n",
    "    return closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(mask, rgb):\n",
    "    # Apply the mask to the RGB image\n",
    "    mask_overlay = np.zeros_like(rgb)\n",
    "    mask_overlay[:, :, 0] = 128  # Red channel for purple\n",
    "    mask_overlay[:, :, 1] = 0  # Green channel for purple\n",
    "    mask_overlay[:, :, 2] = 128  # Blue channel for purple\n",
    "\n",
    "    # Apply the filtered mask to the mask overlay\n",
    "    mask_overlay[mask != 1] = [0, 0, 0]\n",
    "\n",
    "    # Create the inverse mask\n",
    "    inverse_mask = np.logical_not(mask).astype(np.uint8)\n",
    "\n",
    "    # Create an inverse mask overlay with purple color\n",
    "    inverse_mask_overlay = np.zeros_like(rgb)\n",
    "    inverse_mask_overlay[:, :, 0] = 128  # Red channel for purple\n",
    "    inverse_mask_overlay[:, :, 1] = 0  # Green channel for purple\n",
    "    inverse_mask_overlay[:, :, 2] = 128  # Blue channel for purple\n",
    "\n",
    "    # Apply the inverse mask to the inverse mask overlay\n",
    "    inverse_mask_overlay[mask == 1] = [0, 0, 0]\n",
    "\n",
    "    return mask_overlay, inverse_mask_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_segmentation(rgb, mask_overlay, inverse_mask_overlay):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    plt.sca(ax[0])\n",
    "    plt.imshow(rgb)\n",
    "    plt.axis('off')\n",
    "    plt.title('RGB')\n",
    "\n",
    "    plt.sca(ax[1])\n",
    "    plt.imshow(rgb)\n",
    "    plt.imshow(mask_overlay, alpha=0.5)\n",
    "    plt.axis('off')\n",
    "    plt.title('vegetation segmentation')\n",
    "\n",
    "    plt.sca(ax[2])\n",
    "    plt.imshow(rgb)\n",
    "    plt.imshow(inverse_mask_overlay, alpha=0.5)\n",
    "    plt.axis('off')\n",
    "    plt.title('non-veg segmentation')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    print(f\"Processing image: {image_path}\")\n",
    "    # Get the bands of the image\n",
    "    blue, green, red, rgb = get_bands(image_path)\n",
    "    # Get the metadata of the image\n",
    "    metadata = get_metadata(image_path)\n",
    "    # Get the GSD of the image\n",
    "    gsd, gsd_tree = get_gsd(metadata)\n",
    "    # Get the kernel size for morphological operations\n",
    "    area_of_tree, kernel_size = get_kernel_size(gsd_tree)\n",
    "    # Calculate the VARI index\n",
    "    vari = get_vari(blue, green, red)\n",
    "    # Generate the vegetation and non-vegetation masks\n",
    "    vegetation_mask, non_vegetation_mask = threshold(vari)\n",
    "    # Apply smoothing and morphological operations to the vegetation mask\n",
    "    smoothed_mask = smoothing(vegetation_mask)\n",
    "    # Apply morphological operations to the smoothed mask\n",
    "    filtered_mask = morphological_operations(smoothed_mask, kernel_size)\n",
    "    # Apply the mask to the RGB image\n",
    "    mask_overlay, inverse_mask_overlay = segmentation(filtered_mask, rgb)\n",
    "\n",
    "    return rgb, gsd, area_of_tree, vegetation_mask, mask_overlay, inverse_mask_overlay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Define both potential file paths\n",
    "image_path = \"/content/DJI_0876.JPG\" if os.path.exists(\n",
    "    \"/content/DJI_0876.JPG\"\n",
    ") else \"data/presentation/8928dec4ddbffff/DJI_0876.JPG\"\n",
    "# Process the image\n",
    "rgb, gsd, area_of_tree, vegetation_mask, mask_overlay, inverse_mask_overlay = process_image(\n",
    "    image_path)\n",
    "visualize_segmentation(rgb, mask_overlay, inverse_mask_overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Define primary and secondary paths\n",
    "primary_path = '/content/'\n",
    "secondary_path = 'data/presentation/*/*/'\n",
    "\n",
    "# Find images in both paths\n",
    "primary_images = glob.glob(os.path.join(primary_path, '**/*.JPG'),\n",
    "                           recursive=True)\n",
    "secondary_images = glob.glob(os.path.join(secondary_path, '*.JPG'))\n",
    "\n",
    "# Combine both lists, ensuring no duplicates\n",
    "images = list(set(primary_images + secondary_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 0\n",
    "total_trees = 0\n",
    "for image_path in images:\n",
    "    rgb, gsd, area_of_tree, vegetation_mask, mask_overlay, inverse_mask_overlay = process_image(\n",
    "        image_path)\n",
    "    num_vegetation_pixels = np.nansum(vegetation_mask)\n",
    "    n_trees = num_vegetation_pixels / (\n",
    "        area_of_tree)  # multiplying by 3 to account for overest\n",
    "    print(f\"Number of trees: {n_trees}\")\n",
    "\n",
    "    visualize_segmentation(rgb, mask_overlay, inverse_mask_overlay)\n",
    "\n",
    "    total_trees += n_trees\n",
    "    num_images += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate carbon absorbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of trees in the image: number of vegetation pixels / area of tree\n",
    "avg_n_trees = total_trees / num_images\n",
    "print(f'Average number of trees per scene: {n_trees:.0f}')\n",
    "\n",
    "# CO2 absorbed per tree in kg (https://ecotree.green/en/how-much-co2-does-a-tree-absorb#:~:text=A%20tree%20absorbs%20approximately%2025kg%20of%20CO2%20per%20year&text=But%20really%20a%20tree%20absorbs,a%20tree%20absorbs%20so%20interesting.)\n",
    "carbon_absorbed_per_tree = 25\n",
    "# Calculate the amount of carbon absorbed by the trees\n",
    "carbon_absorbed = n_trees * carbon_absorbed_per_tree\n",
    "print(f'Average carbon absorbed per scene: {carbon_absorbed:.0f} kg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrapolate for a city\n",
    "First let's find the footprint of the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total pixels\n",
    "total_pixels = rgb.size / 3\n",
    "# Since the camera is pointed down we can assume the footprint is a rectangle\n",
    "# Calculate the footprint of the camera\n",
    "footprint_area = total_pixels * gsd**2\n",
    "\n",
    "print(f'Footprint area: {footprint_area:.2f} m^2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrapolate the carbon absorbed by the city (Vancouver, BC, Canada)\n",
    "area = 115.18 * 1000 * 1000  # 115.18km^2\n",
    "\n",
    "num_scenes = area / footprint_area\n",
    "\n",
    "print(f'Number of scenes to cover city: {num_scenes:.0f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the carbon absorbed by the city\n",
    "carbon_absorbed_city = carbon_absorbed * num_scenes\n",
    "\n",
    "print(f'Amount of carbon absorbed by the city: {carbon_absorbed_city:.0f} kg')\n",
    "print(f'Trees absorb {carbon_absorbed_city / 1000:.0f} tonnes of CO2 per year')\n",
    "print(f'City of Vancouver emits 28,000 tonnes of CO2 per year')\n",
    "print(\n",
    "    f'Trees absorb {carbon_absorbed_city / 1000 / 28e3*100:.2f}% of the CO2 emitted by the city'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The City of Vancouver emits 28,048 tonnes CO2e ([reference](https://metrovancouver.org/services/air-quality-climate-action/Documents/annual-corporate-energy-and-greenhouse-gas-emissions-management-report-2018-2022.pdf)). That means that these trees are likely absorbing ~16% of Vancouver's greenhouse gases!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawbacks\n",
    "Here let's talk about and show where this method fails:\n",
    "- Segmentation method heavily dependant on: colour of the tree, shadows, sensor calibration, time of day, lighting, weather, seasons, tree species, size of tree, shape of tree?\n",
    "  - Adaptive thresholding helps with variable lighting conditions\n",
    "  - Temporal analysis would help distinguishing between different types of vegetation\n",
    "- Difficult to parse trees from grass and shrubs\n",
    "  - Could use texture analysis to parse these out  \n",
    "- Counting trees heavily dependant of tree size estimate\n",
    "- Carbon capture only an estimate\n",
    "- Working with small number statistics, extrapolation is uncertain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scipy2024-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
